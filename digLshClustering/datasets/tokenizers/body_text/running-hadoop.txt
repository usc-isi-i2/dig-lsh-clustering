1. MR job for tokenizing body text
nohup time hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \
    -D mapred.map.tasks=100 \
    -D mapred.reduce.tasks=100 \
    -libjars /test/karma-mr.jar \
    -file /dig-lsh-clustering/gen_clusters/body_text/mr_body_mapper.py \
    -mapper /dig-lsh-clustering/gen_clusters/body_text/mr_body_mapper.py \
    -file /dig-lsh-clustering/gen_clusters/body_text/mr_body_reducer.py \
    -reducer /dig-lsh-clustering/gen_clusters/body_text/mr_body_reducer.py \
    -input /user/worker/coordinate/istr40m/devel01/* \
    -output dig-40m-body-text \
    -inputformat edu.isi.karma.mapreduce.inputformat.SequenceFileAsJSONInputBatchFormat &


2. MR job for computing similarities from the LSH-Key-Minhashes file
nohup time hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \
    -D mapred.map.tasks=100 \
    -D mapred.reduce.tasks=100 \
    -file /home/ubuntu/dig-lsh-clustering/cluster_mapper.py \
    -mapper /home/ubuntu/dig-lsh-clustering/cluster_mapper.py \
    -file /home/ubuntu/dig-lsh-clustering/cluster_reducer.py \
    -reducer /home/ubuntu/dig-lsh-clustering/cluster_reducer.py \
    -input /user/ubuntu/dig-lsh/40m/lsh/* \
    -output /user/ubuntu/dig-lsh/40m/sim2 &

3. Remove the duplicates
nohup time hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \
    -D mapred.map.tasks=200 \
    -D mapred.reduce.tasks=100 \
    -file /home/ubuntu/dig-lsh-clustering/cluster_dedup_mapper.py \
    -mapper /home/ubuntu/dig-lsh-clustering/cluster_dedup_mapper.py \
    -file /home/ubuntu/dig-lsh-clustering/cluster_dedup_reducer.py \
    -reducer /home/ubuntu/dig-lsh-clustering/cluster_dedup_reducer.py \
    -input /user/ubuntu/dig-lsh/40m/sim/* \
    -output /user/ubuntu/dig-lsh/40m/similar_body &


4. COnvert the output to JSOn
nohup time hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \
    -D mapred.map.tasks=200 \
    -D mapred.reduce.tasks=100 \
    -file /home/ubuntu/dig-lsh-clustering/cluster_jsonoutput_mapper.py \
    -mapper /home/ubuntu/dig-lsh-clustering/cluster_jsonoutput_mapper.py \
    -file /home/ubuntu/dig-lsh-clustering/cluster_jsonoutput_reducer.py \
    -reducer /home/ubuntu/dig-lsh-clustering/cluster_jsonoutput_reducer.py \
    -input /user/ubuntu/dig-lsh/40m/similar_body/* \
    -output /user/worker/ingest/istr40m/similar_body \
    -outputformat org.apache.avro.mapred.AvroTextOutputFormat &



Extra: Find the number of unique ads
nohup time hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \
    -D mapred.map.tasks=200 \
    -D mapred.reduce.tasks=100 \
    -file /home/ubuntu/dig-lsh-clustering/count_mapper.py \
    -mapper /home/ubuntu/dig-lsh-clustering/count_mapper.py \
    -file /home/ubuntu/dig-lsh-clustering/count_reducer2.py \
    -reducer /home/ubuntu/dig-lsh-clustering/count_reducer2.py \
    -input /user/worker/ingest/istr40m/similar_body/* \
    -output /user/ubuntu/dig-lsh/40m/ad_urls &

nohup time hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \
    -D mapred.map.tasks=200 \
    -D mapred.reduce.tasks=1 \
    -file /home/ubuntu/dig-lsh-clustering/cluster_mapper.py \
    -mapper /home/ubuntu/dig-lsh-clustering/cluster_mapper.py \
    -file /home/ubuntu/dig-lsh-clustering/count_reducer.py \
    -reducer /home/ubuntu/dig-lsh-clustering/count_reducer.py \
    -input /user/ubuntu/dig-lsh/40m/ad_urls/* \
    -output /user/ubuntu/dig-lsh/40m/num_unique_ads &
