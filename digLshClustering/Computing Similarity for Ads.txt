1. Tokenize Body Text - 35 mins @DT
------------------------------------
#Tokenize the 50m dump - 30 mins @DT
nohup time hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \
    -D mapred.map.tasks=100 \
    -D mapred.reduce.tasks=1 \
    -libjars dig-lsh-clustering/karma-mr.jar \
    -file dig-lsh-clustering/tokenizer/body_text/mr_body_mapper.py \
    -mapper dig-lsh-clustering/tokenizer/body_text/mr_body_mapper.py \
    -file dig-lsh-clustering/tokenizer/body_text/mr_body_reducer.py \
    -reducer dig-lsh-clustering/tokenizer/body_text/mr_body_reducer.py \
    -input /user/worker/cleaner/2015-04-01/pilot/* \
    -output /user/ubuntu/dig-lsh/50m/tokens/1 \
    -inputformat edu.isi.karma.mapreduce.inputformat.SequenceFileAsJSONInputBatchFormat &

#Tokenize the incrementals - 4 mins @DT
nohup time hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \
    -D mapred.map.tasks=100 \
    -D mapred.reduce.tasks=1 \
    -libjars dig-lsh-clustering/karma-mr.jar \
    -file dig-lsh-clustering/tokenizer/body_text/mr_body_mapper.py \
    -mapper dig-lsh-clustering/tokenizer/body_text/mr_body_mapper.py \
    -file dig-lsh-clustering/tokenizer/body_text/mr_body_reducer.py \
    -reducer dig-lsh-clustering/tokenizer/body_text/mr_body_reducer.py \
    -input /user/worker/cleaner/incremental/pilot/refactor/* \
    -output /user/ubuntu/dig-lsh/50m/tokens/2 \
    -inputformat edu.isi.karma.mapreduce.inputformat.SequenceFileAsJSONInputBatchFormat &

2. Generate LSH Keys - 1hrs, 38mins@DT
---------------------------------------
nohup time hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \
    -D mapred.map.tasks=100 \
    -D mapred.reduce.tasks=100 \
    -file /home/ubuntu/dig-lsh-clustering/hasher/mr_str_lsh_mapper.py \
    -mapper /home/ubuntu/dig-lsh-clustering/hasher/mr_str_lsh_mapper.py \
    -file /home/ubuntu/dig-lsh-clustering/hasher/mr_lsh_reducer.py \
    -reducer /home/ubuntu/dig-lsh-clustering/hasher/mr_lsh_reducer.py \
    -input /user/ubuntu/dig-lsh/50m/tokens/* \
    -output /user/ubuntu/dig-lsh/50m/lsh &


3. Compute the Key - Clusterid file - 16mins@DT -> 20,852,587 clusters, 7GB
-----------------------------------------------
nohup time hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \
    -D mapred.map.tasks=100 \
    -D mapred.reduce.tasks=100 \
    -file /home/ubuntu/dig-lsh-clustering/clusterer/mr_key_clusterid_mapper.py \
    -mapper /home/ubuntu/dig-lsh-clustering/clusterer/mr_key_clusterid_mapper.py \
    -file /home/ubuntu/dig-lsh-clustering/clusterer/mr_key_clusterid_reducer.py \
    -reducer /home/ubuntu/dig-lsh-clustering/clusterer/mr_key_clusterid_reducer.py \
    -input /user/ubuntu/dig-lsh/50m/lsh/* \
    -output /user/ubuntu/dig-lsh/50m/key-clusterid &

4. Compute the LSH-Clusterid-Minhash file - 53mins@DT
------------------------------------------
nohup time hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \
    -D mapred.map.tasks=100 \
    -D mapred.reduce.tasks=500 \
    -file /home/ubuntu/dig-lsh-clustering/clusterer/mr_lsh_clusterid_mapper.py \
    -mapper /home/ubuntu/dig-lsh-clustering/clusterer/mr_lsh_clusterid_mapper.py \
    -file /home/ubuntu/dig-lsh-clustering/clusterer/mr_lsh_clusterid_reducer.py \
    -reducer /home/ubuntu/dig-lsh-clustering/clusterer/mr_lsh_clusterid_reducer.py \
    -input /user/ubuntu/dig-lsh/50m/lsh/* \
    -output /user/ubuntu/dig-lsh/50m/lsh-clusterid &

5. Compute the Cluster-id-x Cluster-id-y score cluster-x-size cluster-y-size file - 10hrs, 1mins, 35sec
-----------------------------------------------------------------------------------
nohup time hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \
    -D mapred.map.tasks=100 \
    -D mapred.reduce.tasks=500 \
    -file /home/ubuntu/dig-lsh-clustering/clusterer/mr_cluster_similarity_mapper.py \
    -mapper /home/ubuntu/dig-lsh-clustering/clusterer/mr_cluster_similarity_mapper.py \
    -file /home/ubuntu/dig-lsh-clustering/clusterer/mr_cluster_similarity_reducer.py \
    -reducer /home/ubuntu/dig-lsh-clustering/clusterer/mr_cluster_similarity_reducer.py \
    -input /user/ubuntu/dig-lsh/50m/lsh-clusterid/* \
    -output /user/ubuntu/dig-lsh/50m/cluster-similarity-dup &

5. Remove the duplicates - 56mins, 14sec -> 4,059,057,260 cluster similarities, 370GB
------------------------
nohup time hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \
    -D mapred.map.tasks=200 \
    -D mapred.reduce.tasks=100 \
    -file /home/ubuntu/dig-lsh-clustering/clusterer/cluster_dedup_mapper.py \
    -mapper /home/ubuntu/dig-lsh-clustering/clusterer/cluster_dedup_mapper.py \
    -file /home/ubuntu/dig-lsh-clustering/clusterer/cluster_dedup_reducer.py \
    -reducer /home/ubuntu/dig-lsh-clustering/clusterer/cluster_dedup_reducer.py \
    -input /user/ubuntu/dig-lsh/50m/cluster-similarity-dup/* \
    -output /user/ubuntu/dig-lsh/50m/cluster-similarity &


7. Convert the output to JSON for the Hue Workflow - 1hrs, 23mins + 1mins, 21sec
---------------------------------------------------
nohup time hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \
    -D mapred.map.tasks=200 \
    -D mapred.reduce.tasks=500 \
    -file /home/ubuntu/dig-lsh-clustering/clusterer/cluster_jsonoutput_mapper.py \
    -mapper /home/ubuntu/dig-lsh-clustering/clusterer/cluster_jsonoutput_mapper.py \
    -file /home/ubuntu/dig-lsh-clustering/clusterer/cluster_jsonoutput_reducer.py \
    -reducer /home/ubuntu/dig-lsh-clustering/clusterer/cluster_jsonoutput_reducer.py \
    -input /user/ubuntu/dig-lsh/50m/cluster-similarity/* \
    -output /user/worker/ingest/istr50m/body-clusters/cluster-similarity &

nohup time hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \
    -D mapred.map.tasks=200 \
    -D mapred.reduce.tasks=500 \
    -file /home/ubuntu/dig-lsh-clustering/clusterer/cluster_jsonoutput_mapper.py \
    -mapper /home/ubuntu/dig-lsh-clustering/clusterer/cluster_jsonoutput_mapper.py \
    -file /home/ubuntu/dig-lsh-clustering/clusterer/cluster_jsonoutput_reducer.py \
    -reducer /home/ubuntu/dig-lsh-clustering/clusterer/cluster_jsonoutput_reducer.py \
    -input /user/ubuntu/dig-lsh/50m/key-clusterid/* \
    -output /user/worker/ingest/istr50m/body-clusters/key-body-clusterid &


Extra: Compute the number of cluster similarities - 5hrs, 36mins
nohup time hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \
    -D mapred.map.tasks=200 \
    -D mapred.reduce.tasks=1 \
    -file /home/ubuntu/dig-lsh-clustering/mr_line_count_mapper.py \
    -mapper /home/ubuntu/dig-lsh-clustering/mr_line_count_mapper.py \
    -file /home/ubuntu/dig-lsh-clustering/mr_line_count_reducer.py \
    -reducer /home/ubuntu/dig-lsh-clustering/mr_line_count_reducer.py \
    -input /user/ubuntu/dig-lsh/50m/cluster-similarity/* \
    -output /user/ubuntu/dig-lsh/50m/cluster-similarity-count &

Extra: COmpute table of cluster-id count - 13mins, 12sec
nohup time hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \
    -D mapred.map.tasks=100 \
    -D mapred.reduce.tasks=500 \
    -file /home/ubuntu/dig-lsh-clustering/clusterer/mr_clusterid_size_mapper.py \
    -mapper /home/ubuntu/dig-lsh-clustering/clusterer/mr_clusterid_size_mapper.py \
    -file /home/ubuntu/dig-lsh-clustering/clusterer/mr_clusterid_size_reducer.py \
    -reducer /home/ubuntu/dig-lsh-clustering/clusterer/mr_clusterid_size_reducer.py \
    -input /user/ubuntu/dig-lsh/50m/lsh-clusterid/* \
    -output /user/ubuntu/dig-lsh/50m/clusterid-size &

Extra: Compute the number of clusters - 2mins, 19sec
nohup time hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \
    -D mapred.map.tasks=200 \
    -D mapred.reduce.tasks=1 \
    -file /home/ubuntu/dig-lsh-clustering/mr_line_count_mapper.py \
    -mapper /home/ubuntu/dig-lsh-clustering/mr_line_count_mapper.py \
    -file /home/ubuntu/dig-lsh-clustering/mr_line_count_reducer.py \
    -reducer /home/ubuntu/dig-lsh-clustering/mr_line_count_reducer.py \
    -input /user/ubuntu/dig-lsh/50m/clusterid-size/* \
    -output /user/ubuntu/dig-lsh/50m/clusterid-size-count &

nohup time hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \
    -D mapred.map.tasks=500 \
    -D mapred.reduce.tasks=500 \
    -file /home/ubuntu/dig-lsh-clustering/mr_line_count_mapper.py \
    -mapper /home/ubuntu/dig-lsh-clustering/mr_line_count_mapper.py \
    -file /home/ubuntu/dig-lsh-clustering/mr_find_cluster_reducer.py \
    -reducer /home/ubuntu/dig-lsh-clustering/mr_find_cluster_reducer.py \
    -input /user/ubuntu/dig-lsh/50m/key-clusterid/* \
    -output /user/ubuntu/dig-lsh/50m/clusterid-000a859879e68819b77570b241fa9c63b7b005e9 &
